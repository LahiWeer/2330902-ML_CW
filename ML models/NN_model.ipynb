{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LahiWeer/2330902-ML_CW/blob/master/ML%20models/NN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "wlf1vWnQL3B7"
      },
      "id": "wlf1vWnQL3B7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the dataset\n",
        "data_url = 'https://raw.githubusercontent.com/LahiWeer/2330902-ML_CW/refs/heads/master/Preprocessing/resampled_and_original_data.csv'\n",
        "data = pd.read_csv(data_url)"
      ],
      "metadata": {
        "id": "GkSqPLSOMOHc"
      },
      "id": "GkSqPLSOMOHc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Step 3: Separate features (X) and target (y)\n",
        "# Replace 'y' with your actual target column name\n",
        "X = data.drop('y', axis=1)\n",
        "y = data['y']\n",
        "\n",
        "# Step 4: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Use StandardScaler instead of MinMaxScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Hyperparameter tuning with Stratified K-Fold Cross Validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.0025)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for early stopping and reduce learning rate\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "# Train model using cross-validation\n",
        "for train_idx, val_idx in kfold.split(X_train_scaled, y_train):\n",
        "    X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        epochs=350,\n",
        "        batch_size=128,\n",
        "        callbacks=[early_stopping, reduce_lr]\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a03fd6-b24f-402e-92a6-c77193ec2ae0",
        "id": "rep00LetggWw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7916 - loss: 0.4547 - val_accuracy: 0.8436 - val_loss: 0.3526 - learning_rate: 0.0025\n",
            "Epoch 2/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3652 - val_accuracy: 0.8447 - val_loss: 0.3485 - learning_rate: 0.0025\n",
            "Epoch 3/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.3525 - val_accuracy: 0.8475 - val_loss: 0.3440 - learning_rate: 0.0025\n",
            "Epoch 4/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.3454 - val_accuracy: 0.8478 - val_loss: 0.3411 - learning_rate: 0.0025\n",
            "Epoch 5/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.3412 - val_accuracy: 0.8514 - val_loss: 0.3391 - learning_rate: 0.0025\n",
            "Epoch 6/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.3392 - val_accuracy: 0.8529 - val_loss: 0.3378 - learning_rate: 0.0025\n",
            "Epoch 7/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 0.3374 - val_accuracy: 0.8516 - val_loss: 0.3331 - learning_rate: 0.0025\n",
            "Epoch 8/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.3337 - val_accuracy: 0.8501 - val_loss: 0.3379 - learning_rate: 0.0025\n",
            "Epoch 9/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.3296 - val_accuracy: 0.8553 - val_loss: 0.3310 - learning_rate: 0.0025\n",
            "Epoch 10/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.3342 - val_accuracy: 0.8545 - val_loss: 0.3282 - learning_rate: 0.0025\n",
            "Epoch 11/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.3283 - val_accuracy: 0.8572 - val_loss: 0.3256 - learning_rate: 0.0025\n",
            "Epoch 12/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3281 - val_accuracy: 0.8573 - val_loss: 0.3257 - learning_rate: 0.0025\n",
            "Epoch 13/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3239 - val_accuracy: 0.8541 - val_loss: 0.3300 - learning_rate: 0.0025\n",
            "Epoch 14/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.3260 - val_accuracy: 0.8557 - val_loss: 0.3260 - learning_rate: 0.0025\n",
            "Epoch 15/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3222 - val_accuracy: 0.8567 - val_loss: 0.3226 - learning_rate: 0.0025\n",
            "Epoch 16/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3226 - val_accuracy: 0.8565 - val_loss: 0.3245 - learning_rate: 0.0025\n",
            "Epoch 17/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8669 - loss: 0.3226 - val_accuracy: 0.8586 - val_loss: 0.3220 - learning_rate: 0.0025\n",
            "Epoch 18/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.3227 - val_accuracy: 0.8595 - val_loss: 0.3260 - learning_rate: 0.0025\n",
            "Epoch 19/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.3155 - val_accuracy: 0.8599 - val_loss: 0.3211 - learning_rate: 0.0025\n",
            "Epoch 20/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.3217 - val_accuracy: 0.8581 - val_loss: 0.3210 - learning_rate: 0.0025\n",
            "Epoch 21/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3123 - val_accuracy: 0.8617 - val_loss: 0.3216 - learning_rate: 0.0025\n",
            "Epoch 22/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.3114 - val_accuracy: 0.8630 - val_loss: 0.3197 - learning_rate: 0.0025\n",
            "Epoch 23/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.3183 - val_accuracy: 0.8603 - val_loss: 0.3203 - learning_rate: 0.0025\n",
            "Epoch 24/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8700 - loss: 0.3112 - val_accuracy: 0.8625 - val_loss: 0.3178 - learning_rate: 0.0025\n",
            "Epoch 25/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.3078 - val_accuracy: 0.8614 - val_loss: 0.3162 - learning_rate: 0.0025\n",
            "Epoch 26/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8701 - loss: 0.3133 - val_accuracy: 0.8655 - val_loss: 0.3161 - learning_rate: 0.0025\n",
            "Epoch 27/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3117 - val_accuracy: 0.8647 - val_loss: 0.3161 - learning_rate: 0.0025\n",
            "Epoch 28/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3168 - val_accuracy: 0.8611 - val_loss: 0.3177 - learning_rate: 0.0025\n",
            "Epoch 29/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3076 - val_accuracy: 0.8643 - val_loss: 0.3157 - learning_rate: 0.0025\n",
            "Epoch 30/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3140 - val_accuracy: 0.8657 - val_loss: 0.3144 - learning_rate: 0.0025\n",
            "Epoch 31/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8704 - loss: 0.3118 - val_accuracy: 0.8654 - val_loss: 0.3133 - learning_rate: 0.0025\n",
            "Epoch 32/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.3050 - val_accuracy: 0.8642 - val_loss: 0.3146 - learning_rate: 0.0025\n",
            "Epoch 33/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.3068 - val_accuracy: 0.8660 - val_loss: 0.3121 - learning_rate: 0.0025\n",
            "Epoch 34/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8722 - loss: 0.3036 - val_accuracy: 0.8638 - val_loss: 0.3123 - learning_rate: 0.0025\n",
            "Epoch 35/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.3060 - val_accuracy: 0.8644 - val_loss: 0.3149 - learning_rate: 0.0025\n",
            "Epoch 36/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8723 - loss: 0.3040 - val_accuracy: 0.8641 - val_loss: 0.3145 - learning_rate: 0.0025\n",
            "Epoch 37/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.3020 - val_accuracy: 0.8673 - val_loss: 0.3099 - learning_rate: 0.0025\n",
            "Epoch 38/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.2999 - val_accuracy: 0.8663 - val_loss: 0.3101 - learning_rate: 0.0025\n",
            "Epoch 39/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.2966 - val_accuracy: 0.8664 - val_loss: 0.3091 - learning_rate: 0.0025\n",
            "Epoch 40/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3022 - val_accuracy: 0.8691 - val_loss: 0.3088 - learning_rate: 0.0025\n",
            "Epoch 41/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3111 - val_accuracy: 0.8668 - val_loss: 0.3078 - learning_rate: 0.0025\n",
            "Epoch 42/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3027 - val_accuracy: 0.8661 - val_loss: 0.3106 - learning_rate: 0.0025\n",
            "Epoch 43/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.3014 - val_accuracy: 0.8656 - val_loss: 0.3085 - learning_rate: 0.0025\n",
            "Epoch 44/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.3004 - val_accuracy: 0.8652 - val_loss: 0.3126 - learning_rate: 0.0025\n",
            "Epoch 45/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.3062 - val_accuracy: 0.8700 - val_loss: 0.3086 - learning_rate: 0.0025\n",
            "Epoch 46/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.3005 - val_accuracy: 0.8656 - val_loss: 0.3089 - learning_rate: 0.0025\n",
            "Epoch 47/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.2918 - val_accuracy: 0.8689 - val_loss: 0.3044 - learning_rate: 0.0012\n",
            "Epoch 48/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.2947 - val_accuracy: 0.8689 - val_loss: 0.3034 - learning_rate: 0.0012\n",
            "Epoch 49/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.2911 - val_accuracy: 0.8708 - val_loss: 0.3031 - learning_rate: 0.0012\n",
            "Epoch 50/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2910 - val_accuracy: 0.8716 - val_loss: 0.3028 - learning_rate: 0.0012\n",
            "Epoch 51/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8783 - loss: 0.2898 - val_accuracy: 0.8709 - val_loss: 0.3025 - learning_rate: 0.0012\n",
            "Epoch 52/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.2905 - val_accuracy: 0.8711 - val_loss: 0.3038 - learning_rate: 0.0012\n",
            "Epoch 53/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.2886 - val_accuracy: 0.8716 - val_loss: 0.3028 - learning_rate: 0.0012\n",
            "Epoch 54/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.2866 - val_accuracy: 0.8712 - val_loss: 0.3026 - learning_rate: 0.0012\n",
            "Epoch 55/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2852 - val_accuracy: 0.8724 - val_loss: 0.3009 - learning_rate: 0.0012\n",
            "Epoch 56/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8798 - loss: 0.2875 - val_accuracy: 0.8737 - val_loss: 0.3020 - learning_rate: 0.0012\n",
            "Epoch 57/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8800 - loss: 0.2926 - val_accuracy: 0.8733 - val_loss: 0.3013 - learning_rate: 0.0012\n",
            "Epoch 58/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.2865 - val_accuracy: 0.8746 - val_loss: 0.3008 - learning_rate: 0.0012\n",
            "Epoch 59/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.2910 - val_accuracy: 0.8749 - val_loss: 0.2991 - learning_rate: 0.0012\n",
            "Epoch 60/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2854 - val_accuracy: 0.8763 - val_loss: 0.2997 - learning_rate: 0.0012\n",
            "Epoch 61/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.2886 - val_accuracy: 0.8735 - val_loss: 0.2992 - learning_rate: 0.0012\n",
            "Epoch 62/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.2865 - val_accuracy: 0.8751 - val_loss: 0.2979 - learning_rate: 0.0012\n",
            "Epoch 63/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.2811 - val_accuracy: 0.8764 - val_loss: 0.2990 - learning_rate: 0.0012\n",
            "Epoch 64/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2814 - val_accuracy: 0.8740 - val_loss: 0.2996 - learning_rate: 0.0012\n",
            "Epoch 65/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.2857 - val_accuracy: 0.8740 - val_loss: 0.3000 - learning_rate: 0.0012\n",
            "Epoch 66/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.2796 - val_accuracy: 0.8755 - val_loss: 0.2974 - learning_rate: 0.0012\n",
            "Epoch 67/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.2822 - val_accuracy: 0.8766 - val_loss: 0.2995 - learning_rate: 0.0012\n",
            "Epoch 68/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.2762 - val_accuracy: 0.8762 - val_loss: 0.2989 - learning_rate: 0.0012\n",
            "Epoch 69/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.2852 - val_accuracy: 0.8780 - val_loss: 0.2960 - learning_rate: 0.0012\n",
            "Epoch 70/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.2849 - val_accuracy: 0.8743 - val_loss: 0.2993 - learning_rate: 0.0012\n",
            "Epoch 71/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.2790 - val_accuracy: 0.8771 - val_loss: 0.2984 - learning_rate: 0.0012\n",
            "Epoch 72/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.2786 - val_accuracy: 0.8771 - val_loss: 0.2978 - learning_rate: 0.0012\n",
            "Epoch 73/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.2734 - val_accuracy: 0.8775 - val_loss: 0.2950 - learning_rate: 0.0012\n",
            "Epoch 74/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8839 - loss: 0.2822 - val_accuracy: 0.8756 - val_loss: 0.2966 - learning_rate: 0.0012\n",
            "Epoch 75/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2829 - val_accuracy: 0.8756 - val_loss: 0.2967 - learning_rate: 0.0012\n",
            "Epoch 76/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.2747 - val_accuracy: 0.8763 - val_loss: 0.2968 - learning_rate: 0.0012\n",
            "Epoch 77/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.2847 - val_accuracy: 0.8785 - val_loss: 0.2949 - learning_rate: 0.0012\n",
            "Epoch 78/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.2771 - val_accuracy: 0.8765 - val_loss: 0.2948 - learning_rate: 0.0012\n",
            "Epoch 79/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.2807 - val_accuracy: 0.8786 - val_loss: 0.2944 - learning_rate: 0.0012\n",
            "Epoch 80/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2758 - val_accuracy: 0.8767 - val_loss: 0.2971 - learning_rate: 0.0012\n",
            "Epoch 81/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2762 - val_accuracy: 0.8762 - val_loss: 0.2965 - learning_rate: 0.0012\n",
            "Epoch 82/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.2790 - val_accuracy: 0.8805 - val_loss: 0.2953 - learning_rate: 0.0012\n",
            "Epoch 83/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.2805 - val_accuracy: 0.8774 - val_loss: 0.2961 - learning_rate: 0.0012\n",
            "Epoch 84/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.2800 - val_accuracy: 0.8777 - val_loss: 0.2958 - learning_rate: 0.0012\n",
            "Epoch 85/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8869 - loss: 0.2730 - val_accuracy: 0.8797 - val_loss: 0.2939 - learning_rate: 6.2500e-04\n",
            "Epoch 86/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.2789 - val_accuracy: 0.8800 - val_loss: 0.2936 - learning_rate: 6.2500e-04\n",
            "Epoch 87/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2811 - val_accuracy: 0.8803 - val_loss: 0.2933 - learning_rate: 6.2500e-04\n",
            "Epoch 88/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.2707 - val_accuracy: 0.8807 - val_loss: 0.2934 - learning_rate: 6.2500e-04\n",
            "Epoch 89/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8865 - loss: 0.2765 - val_accuracy: 0.8811 - val_loss: 0.2926 - learning_rate: 6.2500e-04\n",
            "Epoch 90/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2759 - val_accuracy: 0.8785 - val_loss: 0.2936 - learning_rate: 6.2500e-04\n",
            "Epoch 91/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2755 - val_accuracy: 0.8805 - val_loss: 0.2919 - learning_rate: 6.2500e-04\n",
            "Epoch 92/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.2678 - val_accuracy: 0.8794 - val_loss: 0.2943 - learning_rate: 6.2500e-04\n",
            "Epoch 93/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2716 - val_accuracy: 0.8797 - val_loss: 0.2932 - learning_rate: 6.2500e-04\n",
            "Epoch 94/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.2698 - val_accuracy: 0.8800 - val_loss: 0.2941 - learning_rate: 6.2500e-04\n",
            "Epoch 95/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2742 - val_accuracy: 0.8801 - val_loss: 0.2922 - learning_rate: 6.2500e-04\n",
            "Epoch 96/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2720 - val_accuracy: 0.8786 - val_loss: 0.2935 - learning_rate: 6.2500e-04\n",
            "Epoch 97/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.2703 - val_accuracy: 0.8811 - val_loss: 0.2919 - learning_rate: 3.1250e-04\n",
            "Epoch 98/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2643 - val_accuracy: 0.8811 - val_loss: 0.2919 - learning_rate: 3.1250e-04\n",
            "Epoch 99/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2713 - val_accuracy: 0.8816 - val_loss: 0.2917 - learning_rate: 3.1250e-04\n",
            "Epoch 100/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.2677 - val_accuracy: 0.8803 - val_loss: 0.2915 - learning_rate: 3.1250e-04\n",
            "Epoch 101/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2677 - val_accuracy: 0.8815 - val_loss: 0.2914 - learning_rate: 3.1250e-04\n",
            "Epoch 102/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.2703 - val_accuracy: 0.8814 - val_loss: 0.2911 - learning_rate: 3.1250e-04\n",
            "Epoch 103/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2664 - val_accuracy: 0.8825 - val_loss: 0.2900 - learning_rate: 3.1250e-04\n",
            "Epoch 104/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.2634 - val_accuracy: 0.8834 - val_loss: 0.2904 - learning_rate: 3.1250e-04\n",
            "Epoch 105/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2709 - val_accuracy: 0.8822 - val_loss: 0.2910 - learning_rate: 3.1250e-04\n",
            "Epoch 106/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.2668 - val_accuracy: 0.8824 - val_loss: 0.2907 - learning_rate: 3.1250e-04\n",
            "Epoch 107/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8882 - loss: 0.2694 - val_accuracy: 0.8828 - val_loss: 0.2908 - learning_rate: 3.1250e-04\n",
            "Epoch 108/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.2635 - val_accuracy: 0.8825 - val_loss: 0.2912 - learning_rate: 3.1250e-04\n",
            "Epoch 109/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8902 - loss: 0.2652 - val_accuracy: 0.8823 - val_loss: 0.2904 - learning_rate: 1.5625e-04\n",
            "Epoch 110/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.2671 - val_accuracy: 0.8828 - val_loss: 0.2903 - learning_rate: 1.5625e-04\n",
            "Epoch 111/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2660 - val_accuracy: 0.8827 - val_loss: 0.2901 - learning_rate: 1.5625e-04\n",
            "Epoch 112/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2685 - val_accuracy: 0.8836 - val_loss: 0.2900 - learning_rate: 1.5625e-04\n",
            "Epoch 113/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8921 - loss: 0.2647 - val_accuracy: 0.8819 - val_loss: 0.2898 - learning_rate: 1.5625e-04\n",
            "Epoch 114/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.2660 - val_accuracy: 0.8827 - val_loss: 0.2902 - learning_rate: 1.5625e-04\n",
            "Epoch 115/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2662 - val_accuracy: 0.8831 - val_loss: 0.2902 - learning_rate: 1.5625e-04\n",
            "Epoch 116/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.2598 - val_accuracy: 0.8831 - val_loss: 0.2905 - learning_rate: 1.5625e-04\n",
            "Epoch 117/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2670 - val_accuracy: 0.8836 - val_loss: 0.2905 - learning_rate: 1.5625e-04\n",
            "Epoch 118/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2646 - val_accuracy: 0.8836 - val_loss: 0.2903 - learning_rate: 1.5625e-04\n",
            "Epoch 119/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2602 - val_accuracy: 0.8835 - val_loss: 0.2906 - learning_rate: 7.8125e-05\n",
            "Epoch 120/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2652 - val_accuracy: 0.8839 - val_loss: 0.2902 - learning_rate: 7.8125e-05\n",
            "Epoch 121/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2664 - val_accuracy: 0.8841 - val_loss: 0.2901 - learning_rate: 7.8125e-05\n",
            "Epoch 122/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.2652 - val_accuracy: 0.8842 - val_loss: 0.2900 - learning_rate: 7.8125e-05\n",
            "Epoch 123/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.2644 - val_accuracy: 0.8836 - val_loss: 0.2901 - learning_rate: 7.8125e-05\n",
            "Epoch 1/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.2818 - val_accuracy: 0.9101 - val_loss: 0.2273 - learning_rate: 3.9062e-05\n",
            "Epoch 2/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.2801 - val_accuracy: 0.9108 - val_loss: 0.2282 - learning_rate: 3.9062e-05\n",
            "Epoch 3/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.2805 - val_accuracy: 0.9101 - val_loss: 0.2289 - learning_rate: 3.9062e-05\n",
            "Epoch 4/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.2754 - val_accuracy: 0.9105 - val_loss: 0.2289 - learning_rate: 3.9062e-05\n",
            "Epoch 5/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.2761 - val_accuracy: 0.9098 - val_loss: 0.2292 - learning_rate: 3.9062e-05\n",
            "Epoch 6/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.2759 - val_accuracy: 0.9095 - val_loss: 0.2296 - learning_rate: 3.9062e-05\n",
            "Epoch 7/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2759 - val_accuracy: 0.9099 - val_loss: 0.2297 - learning_rate: 1.9531e-05\n",
            "Epoch 8/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.2757 - val_accuracy: 0.9096 - val_loss: 0.2298 - learning_rate: 1.9531e-05\n",
            "Epoch 9/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.2752 - val_accuracy: 0.9095 - val_loss: 0.2300 - learning_rate: 1.9531e-05\n",
            "Epoch 10/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.2708 - val_accuracy: 0.9097 - val_loss: 0.2300 - learning_rate: 1.9531e-05\n",
            "Epoch 11/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.2759 - val_accuracy: 0.9093 - val_loss: 0.2302 - learning_rate: 1.9531e-05\n",
            "Epoch 1/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.2802 - val_accuracy: 0.9133 - val_loss: 0.2270 - learning_rate: 9.7656e-06\n",
            "Epoch 2/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.2806 - val_accuracy: 0.9131 - val_loss: 0.2272 - learning_rate: 9.7656e-06\n",
            "Epoch 3/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8851 - loss: 0.2798 - val_accuracy: 0.9130 - val_loss: 0.2274 - learning_rate: 9.7656e-06\n",
            "Epoch 4/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2787 - val_accuracy: 0.9127 - val_loss: 0.2276 - learning_rate: 9.7656e-06\n",
            "Epoch 5/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.2773 - val_accuracy: 0.9127 - val_loss: 0.2277 - learning_rate: 9.7656e-06\n",
            "Epoch 6/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.2809 - val_accuracy: 0.9127 - val_loss: 0.2279 - learning_rate: 9.7656e-06\n",
            "Epoch 7/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.2798 - val_accuracy: 0.9127 - val_loss: 0.2280 - learning_rate: 4.8828e-06\n",
            "Epoch 8/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.2805 - val_accuracy: 0.9127 - val_loss: 0.2281 - learning_rate: 4.8828e-06\n",
            "Epoch 9/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.2829 - val_accuracy: 0.9129 - val_loss: 0.2282 - learning_rate: 4.8828e-06\n",
            "Epoch 10/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.2746 - val_accuracy: 0.9129 - val_loss: 0.2282 - learning_rate: 4.8828e-06\n",
            "Epoch 11/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.2766 - val_accuracy: 0.9129 - val_loss: 0.2283 - learning_rate: 4.8828e-06\n",
            "Epoch 1/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8859 - loss: 0.2813 - val_accuracy: 0.9092 - val_loss: 0.2313 - learning_rate: 2.4414e-06\n",
            "Epoch 2/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2748 - val_accuracy: 0.9092 - val_loss: 0.2314 - learning_rate: 2.4414e-06\n",
            "Epoch 3/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.2798 - val_accuracy: 0.9092 - val_loss: 0.2314 - learning_rate: 2.4414e-06\n",
            "Epoch 4/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.2782 - val_accuracy: 0.9093 - val_loss: 0.2315 - learning_rate: 2.4414e-06\n",
            "Epoch 5/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.2789 - val_accuracy: 0.9093 - val_loss: 0.2315 - learning_rate: 2.4414e-06\n",
            "Epoch 6/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.2791 - val_accuracy: 0.9093 - val_loss: 0.2316 - learning_rate: 2.4414e-06\n",
            "Epoch 7/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.2794 - val_accuracy: 0.9093 - val_loss: 0.2316 - learning_rate: 1.2207e-06\n",
            "Epoch 8/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8867 - loss: 0.2770 - val_accuracy: 0.9094 - val_loss: 0.2316 - learning_rate: 1.2207e-06\n",
            "Epoch 9/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.2816 - val_accuracy: 0.9094 - val_loss: 0.2316 - learning_rate: 1.2207e-06\n",
            "Epoch 10/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8877 - loss: 0.2779 - val_accuracy: 0.9095 - val_loss: 0.2317 - learning_rate: 1.2207e-06\n",
            "Epoch 1/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.2762 - val_accuracy: 0.9088 - val_loss: 0.2333 - learning_rate: 1.2207e-06\n",
            "Epoch 2/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2787 - val_accuracy: 0.9088 - val_loss: 0.2333 - learning_rate: 1.2207e-06\n",
            "Epoch 3/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.2739 - val_accuracy: 0.9088 - val_loss: 0.2333 - learning_rate: 1.2207e-06\n",
            "Epoch 4/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8859 - loss: 0.2774 - val_accuracy: 0.9088 - val_loss: 0.2333 - learning_rate: 1.2207e-06\n",
            "Epoch 5/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 0.2823 - val_accuracy: 0.9088 - val_loss: 0.2334 - learning_rate: 1.2207e-06\n",
            "Epoch 6/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.2813 - val_accuracy: 0.9088 - val_loss: 0.2334 - learning_rate: 1.2207e-06\n",
            "Epoch 7/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2798 - val_accuracy: 0.9088 - val_loss: 0.2334 - learning_rate: 6.1035e-07\n",
            "Epoch 8/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2741 - val_accuracy: 0.9089 - val_loss: 0.2334 - learning_rate: 6.1035e-07\n",
            "Epoch 9/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.2759 - val_accuracy: 0.9090 - val_loss: 0.2334 - learning_rate: 6.1035e-07\n",
            "Epoch 10/350\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.2786 - val_accuracy: 0.9087 - val_loss: 0.2334 - learning_rate: 6.1035e-07\n"
          ]
        }
      ],
      "id": "rep00LetggWw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Predict on Test Data\n",
        "y_pred_prob = model.predict(X_test_scaled)  # Predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)    # Convert probabilities to binary predictions\n",
        "\n",
        "# Step 8: Evaluate Model\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Hy6LwP28gfsv",
        "outputId": "a299b0ed-597d-4e92-9834-d0e718d46555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Hy6LwP28gfsv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Accuracy: 0.8853003075926825\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.89      6177\n",
            "           1       0.90      0.87      0.88      6177\n",
            "\n",
            "    accuracy                           0.89     12354\n",
            "   macro avg       0.89      0.89      0.89     12354\n",
            "weighted avg       0.89      0.89      0.89     12354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data_url = 'https://raw.githubusercontent.com/LahiWeer/2330902-ML_CW/refs/heads/master/Preprocessing/resampled_and_original_data.csv'\n",
        "data = pd.read_csv(\"resampled_and_original_data.csv\")\n",
        "\n",
        "# Step 2: Separate features (X) and target (y)\n",
        "X = data.drop('y', axis=1)\n",
        "y = data['y']\n",
        "\n",
        "# Step 3: List of columns to scale\n",
        "columns_to_scale = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
        "                    'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed',\n",
        "                    'default', 'housing', 'loan', 'contact', 'month',\n",
        "                    'day_of_week', 'poutcome', 'education']\n",
        "\n",
        "# Step 4: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 5: Apply scaling only to specific columns\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "# Scale only the specified columns\n",
        "X_train_scaled[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "X_test_scaled[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
        "\n",
        "# Step 6: Initialize model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.0025)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for early stopping and reduce learning rate\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "# Step 7: Hyperparameter tuning with Stratified K-Fold Cross Validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for train_idx, val_idx in kfold.split(X_train_scaled, y_train):\n",
        "    X_train_fold, X_val_fold = X_train_scaled.iloc[train_idx], X_train_scaled.iloc[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        epochs=400,\n",
        "        batch_size=128,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )"
      ],
      "metadata": {
        "id": "OOVUktdRBDf_",
        "outputId": "2d9d5acb-a7f5-4f4c-ce70-53bf45cb39ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OOVUktdRBDf_",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7692 - loss: 0.4884 - val_accuracy: 0.8415 - val_loss: 0.3567 - learning_rate: 0.0025\n",
            "Epoch 2/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3740 - val_accuracy: 0.8489 - val_loss: 0.3444 - learning_rate: 0.0025\n",
            "Epoch 3/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3591 - val_accuracy: 0.8495 - val_loss: 0.3386 - learning_rate: 0.0025\n",
            "Epoch 4/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.3483 - val_accuracy: 0.8513 - val_loss: 0.3323 - learning_rate: 0.0025\n",
            "Epoch 5/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 0.3479 - val_accuracy: 0.8524 - val_loss: 0.3347 - learning_rate: 0.0025\n",
            "Epoch 6/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 0.3386 - val_accuracy: 0.8540 - val_loss: 0.3337 - learning_rate: 0.0025\n",
            "Epoch 7/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8569 - loss: 0.3347 - val_accuracy: 0.8560 - val_loss: 0.3289 - learning_rate: 0.0025\n",
            "Epoch 8/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.3349 - val_accuracy: 0.8546 - val_loss: 0.3308 - learning_rate: 0.0025\n",
            "Epoch 9/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.3382 - val_accuracy: 0.8579 - val_loss: 0.3281 - learning_rate: 0.0025\n",
            "Epoch 10/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.3319 - val_accuracy: 0.8582 - val_loss: 0.3236 - learning_rate: 0.0025\n",
            "Epoch 11/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3225 - val_accuracy: 0.8570 - val_loss: 0.3246 - learning_rate: 0.0025\n",
            "Epoch 12/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8639 - loss: 0.3286 - val_accuracy: 0.8583 - val_loss: 0.3276 - learning_rate: 0.0025\n",
            "Epoch 13/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3215 - val_accuracy: 0.8611 - val_loss: 0.3238 - learning_rate: 0.0025\n",
            "Epoch 14/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3223 - val_accuracy: 0.8582 - val_loss: 0.3214 - learning_rate: 0.0025\n",
            "Epoch 15/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8668 - loss: 0.3155 - val_accuracy: 0.8582 - val_loss: 0.3233 - learning_rate: 0.0025\n",
            "Epoch 16/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.3258 - val_accuracy: 0.8608 - val_loss: 0.3224 - learning_rate: 0.0025\n",
            "Epoch 17/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.3143 - val_accuracy: 0.8608 - val_loss: 0.3206 - learning_rate: 0.0025\n",
            "Epoch 18/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3187 - val_accuracy: 0.8601 - val_loss: 0.3165 - learning_rate: 0.0025\n",
            "Epoch 19/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3136 - val_accuracy: 0.8599 - val_loss: 0.3199 - learning_rate: 0.0025\n",
            "Epoch 20/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8719 - loss: 0.3106 - val_accuracy: 0.8622 - val_loss: 0.3189 - learning_rate: 0.0025\n",
            "Epoch 21/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.3137 - val_accuracy: 0.8617 - val_loss: 0.3200 - learning_rate: 0.0025\n",
            "Epoch 22/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.3137 - val_accuracy: 0.8620 - val_loss: 0.3192 - learning_rate: 0.0025\n",
            "Epoch 23/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3128 - val_accuracy: 0.8607 - val_loss: 0.3172 - learning_rate: 0.0025\n",
            "Epoch 24/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8720 - loss: 0.3055 - val_accuracy: 0.8624 - val_loss: 0.3144 - learning_rate: 0.0012\n",
            "Epoch 25/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8752 - loss: 0.3005 - val_accuracy: 0.8631 - val_loss: 0.3122 - learning_rate: 0.0012\n",
            "Epoch 26/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3001 - val_accuracy: 0.8656 - val_loss: 0.3103 - learning_rate: 0.0012\n",
            "Epoch 27/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.2967 - val_accuracy: 0.8646 - val_loss: 0.3097 - learning_rate: 0.0012\n",
            "Epoch 28/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.2993 - val_accuracy: 0.8650 - val_loss: 0.3095 - learning_rate: 0.0012\n",
            "Epoch 29/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.2940 - val_accuracy: 0.8664 - val_loss: 0.3090 - learning_rate: 0.0012\n",
            "Epoch 30/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.3030 - val_accuracy: 0.8661 - val_loss: 0.3074 - learning_rate: 0.0012\n",
            "Epoch 31/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.2913 - val_accuracy: 0.8664 - val_loss: 0.3081 - learning_rate: 0.0012\n",
            "Epoch 32/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2964 - val_accuracy: 0.8687 - val_loss: 0.3062 - learning_rate: 0.0012\n",
            "Epoch 33/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2897 - val_accuracy: 0.8666 - val_loss: 0.3063 - learning_rate: 0.0012\n",
            "Epoch 34/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.2957 - val_accuracy: 0.8678 - val_loss: 0.3059 - learning_rate: 0.0012\n",
            "Epoch 35/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.2900 - val_accuracy: 0.8674 - val_loss: 0.3064 - learning_rate: 0.0012\n",
            "Epoch 36/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8764 - loss: 0.2986 - val_accuracy: 0.8688 - val_loss: 0.3046 - learning_rate: 0.0012\n",
            "Epoch 37/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8772 - loss: 0.2902 - val_accuracy: 0.8666 - val_loss: 0.3054 - learning_rate: 0.0012\n",
            "Epoch 38/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.2873 - val_accuracy: 0.8671 - val_loss: 0.3048 - learning_rate: 0.0012\n",
            "Epoch 39/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8780 - loss: 0.2959 - val_accuracy: 0.8680 - val_loss: 0.3014 - learning_rate: 0.0012\n",
            "Epoch 40/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.2892 - val_accuracy: 0.8705 - val_loss: 0.3009 - learning_rate: 0.0012\n",
            "Epoch 41/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 0.2925 - val_accuracy: 0.8676 - val_loss: 0.3030 - learning_rate: 0.0012\n",
            "Epoch 42/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.2954 - val_accuracy: 0.8692 - val_loss: 0.3036 - learning_rate: 0.0012\n",
            "Epoch 43/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.2868 - val_accuracy: 0.8691 - val_loss: 0.3038 - learning_rate: 0.0012\n",
            "Epoch 44/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.2936 - val_accuracy: 0.8678 - val_loss: 0.3050 - learning_rate: 0.0012\n",
            "Epoch 45/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.2913 - val_accuracy: 0.8702 - val_loss: 0.3026 - learning_rate: 0.0012\n",
            "Epoch 46/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2842 - val_accuracy: 0.8710 - val_loss: 0.3009 - learning_rate: 6.2500e-04\n",
            "Epoch 47/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.2806 - val_accuracy: 0.8707 - val_loss: 0.3008 - learning_rate: 6.2500e-04\n",
            "Epoch 48/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.2801 - val_accuracy: 0.8702 - val_loss: 0.2996 - learning_rate: 6.2500e-04\n",
            "Epoch 49/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.2853 - val_accuracy: 0.8721 - val_loss: 0.2977 - learning_rate: 6.2500e-04\n",
            "Epoch 50/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.2827 - val_accuracy: 0.8736 - val_loss: 0.2989 - learning_rate: 6.2500e-04\n",
            "Epoch 51/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.2809 - val_accuracy: 0.8710 - val_loss: 0.3004 - learning_rate: 6.2500e-04\n",
            "Epoch 52/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2800 - val_accuracy: 0.8721 - val_loss: 0.3004 - learning_rate: 6.2500e-04\n",
            "Epoch 53/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.2881 - val_accuracy: 0.8718 - val_loss: 0.3004 - learning_rate: 6.2500e-04\n",
            "Epoch 54/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2773 - val_accuracy: 0.8736 - val_loss: 0.2998 - learning_rate: 6.2500e-04\n",
            "Epoch 55/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.2828 - val_accuracy: 0.8729 - val_loss: 0.2979 - learning_rate: 3.1250e-04\n",
            "Epoch 56/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.2742 - val_accuracy: 0.8736 - val_loss: 0.2985 - learning_rate: 3.1250e-04\n",
            "Epoch 57/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8867 - loss: 0.2803 - val_accuracy: 0.8742 - val_loss: 0.2981 - learning_rate: 3.1250e-04\n",
            "Epoch 58/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.2779 - val_accuracy: 0.8729 - val_loss: 0.2979 - learning_rate: 3.1250e-04\n",
            "Epoch 59/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.2756 - val_accuracy: 0.8731 - val_loss: 0.2974 - learning_rate: 3.1250e-04\n",
            "Epoch 60/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.2774 - val_accuracy: 0.8724 - val_loss: 0.2973 - learning_rate: 3.1250e-04\n",
            "Epoch 61/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8862 - loss: 0.2792 - val_accuracy: 0.8748 - val_loss: 0.2973 - learning_rate: 3.1250e-04\n",
            "Epoch 62/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.2726 - val_accuracy: 0.8742 - val_loss: 0.2968 - learning_rate: 3.1250e-04\n",
            "Epoch 63/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.2658 - val_accuracy: 0.8736 - val_loss: 0.2962 - learning_rate: 3.1250e-04\n",
            "Epoch 64/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2784 - val_accuracy: 0.8740 - val_loss: 0.2959 - learning_rate: 3.1250e-04\n",
            "Epoch 65/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.2742 - val_accuracy: 0.8747 - val_loss: 0.2964 - learning_rate: 3.1250e-04\n",
            "Epoch 66/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.2804 - val_accuracy: 0.8734 - val_loss: 0.2963 - learning_rate: 3.1250e-04\n",
            "Epoch 67/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2716 - val_accuracy: 0.8747 - val_loss: 0.2963 - learning_rate: 3.1250e-04\n",
            "Epoch 68/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2749 - val_accuracy: 0.8740 - val_loss: 0.2969 - learning_rate: 3.1250e-04\n",
            "Epoch 69/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8867 - loss: 0.2744 - val_accuracy: 0.8736 - val_loss: 0.2971 - learning_rate: 3.1250e-04\n",
            "Epoch 70/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2726 - val_accuracy: 0.8739 - val_loss: 0.2960 - learning_rate: 1.5625e-04\n",
            "Epoch 71/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2717 - val_accuracy: 0.8747 - val_loss: 0.2959 - learning_rate: 1.5625e-04\n",
            "Epoch 72/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.2710 - val_accuracy: 0.8736 - val_loss: 0.2969 - learning_rate: 1.5625e-04\n",
            "Epoch 73/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8859 - loss: 0.2762 - val_accuracy: 0.8752 - val_loss: 0.2956 - learning_rate: 1.5625e-04\n",
            "Epoch 74/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2739 - val_accuracy: 0.8753 - val_loss: 0.2957 - learning_rate: 1.5625e-04\n",
            "Epoch 75/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.2766 - val_accuracy: 0.8754 - val_loss: 0.2955 - learning_rate: 1.5625e-04\n",
            "Epoch 76/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2672 - val_accuracy: 0.8757 - val_loss: 0.2950 - learning_rate: 1.5625e-04\n",
            "Epoch 77/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.2717 - val_accuracy: 0.8750 - val_loss: 0.2953 - learning_rate: 1.5625e-04\n",
            "Epoch 78/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.2697 - val_accuracy: 0.8762 - val_loss: 0.2955 - learning_rate: 1.5625e-04\n",
            "Epoch 79/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2694 - val_accuracy: 0.8764 - val_loss: 0.2952 - learning_rate: 1.5625e-04\n",
            "Epoch 80/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2656 - val_accuracy: 0.8756 - val_loss: 0.2955 - learning_rate: 1.5625e-04\n",
            "Epoch 81/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.2703 - val_accuracy: 0.8769 - val_loss: 0.2956 - learning_rate: 1.5625e-04\n",
            "Epoch 82/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.2722 - val_accuracy: 0.8766 - val_loss: 0.2953 - learning_rate: 7.8125e-05\n",
            "Epoch 83/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.2682 - val_accuracy: 0.8765 - val_loss: 0.2952 - learning_rate: 7.8125e-05\n",
            "Epoch 84/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2697 - val_accuracy: 0.8750 - val_loss: 0.2954 - learning_rate: 7.8125e-05\n",
            "Epoch 85/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.2799 - val_accuracy: 0.8765 - val_loss: 0.2955 - learning_rate: 7.8125e-05\n",
            "Epoch 86/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2641 - val_accuracy: 0.8758 - val_loss: 0.2953 - learning_rate: 7.8125e-05\n",
            "Epoch 1/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.2879 - val_accuracy: 0.9031 - val_loss: 0.2383 - learning_rate: 3.9062e-05\n",
            "Epoch 2/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.2881 - val_accuracy: 0.9040 - val_loss: 0.2388 - learning_rate: 3.9062e-05\n",
            "Epoch 3/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.2847 - val_accuracy: 0.9039 - val_loss: 0.2393 - learning_rate: 3.9062e-05\n",
            "Epoch 4/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2819 - val_accuracy: 0.9035 - val_loss: 0.2399 - learning_rate: 3.9062e-05\n",
            "Epoch 5/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.2870 - val_accuracy: 0.9039 - val_loss: 0.2400 - learning_rate: 3.9062e-05\n",
            "Epoch 6/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.2822 - val_accuracy: 0.9039 - val_loss: 0.2399 - learning_rate: 3.9062e-05\n",
            "Epoch 7/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2796 - val_accuracy: 0.9036 - val_loss: 0.2401 - learning_rate: 1.9531e-05\n",
            "Epoch 8/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.2806 - val_accuracy: 0.9035 - val_loss: 0.2402 - learning_rate: 1.9531e-05\n",
            "Epoch 9/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.2865 - val_accuracy: 0.9035 - val_loss: 0.2403 - learning_rate: 1.9531e-05\n",
            "Epoch 10/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2836 - val_accuracy: 0.9034 - val_loss: 0.2404 - learning_rate: 1.9531e-05\n",
            "Epoch 11/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.2822 - val_accuracy: 0.9029 - val_loss: 0.2407 - learning_rate: 1.9531e-05\n",
            "Epoch 1/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8812 - loss: 0.2911 - val_accuracy: 0.9067 - val_loss: 0.2375 - learning_rate: 9.7656e-06\n",
            "Epoch 2/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.2867 - val_accuracy: 0.9066 - val_loss: 0.2376 - learning_rate: 9.7656e-06\n",
            "Epoch 3/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2836 - val_accuracy: 0.9069 - val_loss: 0.2378 - learning_rate: 9.7656e-06\n",
            "Epoch 4/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.2784 - val_accuracy: 0.9070 - val_loss: 0.2379 - learning_rate: 9.7656e-06\n",
            "Epoch 5/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.2811 - val_accuracy: 0.9069 - val_loss: 0.2380 - learning_rate: 9.7656e-06\n",
            "Epoch 6/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.2871 - val_accuracy: 0.9068 - val_loss: 0.2382 - learning_rate: 9.7656e-06\n",
            "Epoch 7/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.2796 - val_accuracy: 0.9070 - val_loss: 0.2382 - learning_rate: 4.8828e-06\n",
            "Epoch 8/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8851 - loss: 0.2803 - val_accuracy: 0.9066 - val_loss: 0.2383 - learning_rate: 4.8828e-06\n",
            "Epoch 9/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.2822 - val_accuracy: 0.9065 - val_loss: 0.2383 - learning_rate: 4.8828e-06\n",
            "Epoch 10/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.2855 - val_accuracy: 0.9065 - val_loss: 0.2384 - learning_rate: 4.8828e-06\n",
            "Epoch 11/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2819 - val_accuracy: 0.9064 - val_loss: 0.2384 - learning_rate: 4.8828e-06\n",
            "Epoch 1/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2786 - val_accuracy: 0.9048 - val_loss: 0.2405 - learning_rate: 2.4414e-06\n",
            "Epoch 2/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2772 - val_accuracy: 0.9049 - val_loss: 0.2405 - learning_rate: 2.4414e-06\n",
            "Epoch 3/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.2822 - val_accuracy: 0.9048 - val_loss: 0.2406 - learning_rate: 2.4414e-06\n",
            "Epoch 4/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.2839 - val_accuracy: 0.9050 - val_loss: 0.2406 - learning_rate: 2.4414e-06\n",
            "Epoch 5/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.2802 - val_accuracy: 0.9050 - val_loss: 0.2406 - learning_rate: 2.4414e-06\n",
            "Epoch 6/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8823 - loss: 0.2860 - val_accuracy: 0.9050 - val_loss: 0.2407 - learning_rate: 2.4414e-06\n",
            "Epoch 7/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2856 - val_accuracy: 0.9050 - val_loss: 0.2407 - learning_rate: 1.2207e-06\n",
            "Epoch 8/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 0.2778 - val_accuracy: 0.9050 - val_loss: 0.2407 - learning_rate: 1.2207e-06\n",
            "Epoch 9/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.2818 - val_accuracy: 0.9050 - val_loss: 0.2407 - learning_rate: 1.2207e-06\n",
            "Epoch 10/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.2827 - val_accuracy: 0.9049 - val_loss: 0.2407 - learning_rate: 1.2207e-06\n",
            "Epoch 1/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.2837 - val_accuracy: 0.8984 - val_loss: 0.2477 - learning_rate: 1.2207e-06\n",
            "Epoch 2/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.2862 - val_accuracy: 0.8984 - val_loss: 0.2477 - learning_rate: 1.2207e-06\n",
            "Epoch 3/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.2840 - val_accuracy: 0.8983 - val_loss: 0.2477 - learning_rate: 1.2207e-06\n",
            "Epoch 4/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2896 - val_accuracy: 0.8983 - val_loss: 0.2477 - learning_rate: 1.2207e-06\n",
            "Epoch 5/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2883 - val_accuracy: 0.8983 - val_loss: 0.2478 - learning_rate: 1.2207e-06\n",
            "Epoch 6/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.2733 - val_accuracy: 0.8983 - val_loss: 0.2478 - learning_rate: 1.2207e-06\n",
            "Epoch 7/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.2854 - val_accuracy: 0.8984 - val_loss: 0.2478 - learning_rate: 6.1035e-07\n",
            "Epoch 8/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2817 - val_accuracy: 0.8984 - val_loss: 0.2478 - learning_rate: 6.1035e-07\n",
            "Epoch 9/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.2797 - val_accuracy: 0.8984 - val_loss: 0.2478 - learning_rate: 6.1035e-07\n",
            "Epoch 10/400\n",
            "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.2786 - val_accuracy: 0.8984 - val_loss: 0.2478 - learning_rate: 6.1035e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Predict on Test Data\n",
        "y_pred_prob = model.predict(X_test_scaled)  # Predicted probabilities\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)    # Convert probabilities to binary predictions\n",
        "\n",
        "# Step 9: Evaluate Model\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "O9st3jY2BOhG",
        "outputId": "83d70d48-9162-4f02-e2ef-bfe6fc36fe12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "O9st3jY2BOhG",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Accuracy: 0.8831147806378501\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88      6177\n",
            "           1       0.90      0.87      0.88      6177\n",
            "\n",
            "    accuracy                           0.88     12354\n",
            "   macro avg       0.88      0.88      0.88     12354\n",
            "weighted avg       0.88      0.88      0.88     12354\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}