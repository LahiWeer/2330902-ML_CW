{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T14:31:13.855120Z",
     "start_time": "2024-12-22T14:31:13.758621Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = 'processed_bank_data_final.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display initial DataFrame information\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())  # Display the first few rows\n",
    "print(f\"\\nTotal rows in the original DataFrame: {len(df)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   age  job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
      "0   56                0                 0              1               0   \n",
      "1   57                0                 0              0               0   \n",
      "2   37                0                 0              0               0   \n",
      "3   40                0                 0              0               0   \n",
      "4   56                0                 0              0               0   \n",
      "\n",
      "   job_retired  job_self-employed  job_services  job_student  job_technician  \\\n",
      "0            0                  0             0            0               0   \n",
      "1            0                  0             1            0               0   \n",
      "2            0                  0             1            0               0   \n",
      "3            0                  0             0            0               0   \n",
      "4            0                  0             1            0               0   \n",
      "\n",
      "   ...  campaign  pdays  previous  poutcome  emp.var.rate  cons.price.idx  \\\n",
      "0  ...         1    999         0        -1           1.1          93.994   \n",
      "1  ...         1    999         0        -1           1.1          93.994   \n",
      "2  ...         1    999         0        -1           1.1          93.994   \n",
      "3  ...         1    999         0        -1           1.1          93.994   \n",
      "4  ...         1    999         0        -1           1.1          93.994   \n",
      "\n",
      "   cons.conf.idx  euribor3m  nr.employed  y  \n",
      "0          -36.4      4.857       5191.0  0  \n",
      "1          -36.4      4.857       5191.0  0  \n",
      "2          -36.4      4.857       5191.0  0  \n",
      "3          -36.4      4.857       5191.0  0  \n",
      "4          -36.4      4.857       5191.0  0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Total rows in the original DataFrame: 40787\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:32:39.942899Z",
     "start_time": "2024-12-22T14:31:18.604307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find duplicate rows and mark the first occurrence index for duplicates\n",
    "duplicates = df[df.duplicated(keep=False)]  # Get all duplicated rows\n",
    "\n",
    "# Add a new column 'is_duplicate' and 'duplicate_with' to highlight duplicates and show their first occurrence\n",
    "df['is_duplicate'] = ''\n",
    "df['duplicate_with'] = ''\n",
    "\n",
    "# Get the index of the first occurrence of each duplicate\n",
    "first_occurrence_index = df[df.duplicated(keep='first')].index\n",
    "\n",
    "# Loop through the DataFrame to mark duplicates and their first occurrence\n",
    "for idx in first_occurrence_index:\n",
    "    # Find the first occurrence index\n",
    "    first_occurrence = df[df.iloc[:, :].eq(df.iloc[idx, :]).all(axis=1)].index[0]\n",
    "\n",
    "    # Mark the duplicate row and the first occurrence\n",
    "    df.at[idx, 'is_duplicate'] = 'Duplicate'\n",
    "    df.at[idx, 'duplicate_with'] = f\"Row {first_occurrence}\""
   ],
   "id": "6a15e6f85f863125",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:32:40.076726Z",
     "start_time": "2024-12-22T14:32:40.065098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the DataFrame with the new 'is_duplicate' and 'duplicate_with' columns\n",
    "print(\"\\nDataFrame with 'is_duplicate' and 'duplicate_with' columns:\")\n",
    "print(df.head())  # Display the first few rows of the updated DataFrame"
   ],
   "id": "b0aab2476e924ad6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with 'is_duplicate' and 'duplicate_with' columns:\n",
      "   age  job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
      "0   56                0                 0              1               0   \n",
      "1   57                0                 0              0               0   \n",
      "2   37                0                 0              0               0   \n",
      "3   40                0                 0              0               0   \n",
      "4   56                0                 0              0               0   \n",
      "\n",
      "   job_retired  job_self-employed  job_services  job_student  job_technician  \\\n",
      "0            0                  0             0            0               0   \n",
      "1            0                  0             1            0               0   \n",
      "2            0                  0             1            0               0   \n",
      "3            0                  0             0            0               0   \n",
      "4            0                  0             1            0               0   \n",
      "\n",
      "   ...  previous  poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  \\\n",
      "0  ...         0        -1           1.1          93.994          -36.4   \n",
      "1  ...         0        -1           1.1          93.994          -36.4   \n",
      "2  ...         0        -1           1.1          93.994          -36.4   \n",
      "3  ...         0        -1           1.1          93.994          -36.4   \n",
      "4  ...         0        -1           1.1          93.994          -36.4   \n",
      "\n",
      "   euribor3m  nr.employed  y  is_duplicate  duplicate_with  \n",
      "0      4.857       5191.0  0                                \n",
      "1      4.857       5191.0  0                                \n",
      "2      4.857       5191.0  0                                \n",
      "3      4.857       5191.0  0                                \n",
      "4      4.857       5191.0  0                                \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:32:40.134848Z",
     "start_time": "2024-12-22T14:32:40.104309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicate_count}\")"
   ],
   "id": "e2792885ed29458d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 277\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:32:40.428523Z",
     "start_time": "2024-12-22T14:32:40.149651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the updated DataFrame with the new columns to a CSV file\n",
    "output_file_path = 'highlighted_duplicates_with_row_numbers.csv'  # Replace with your desired output file path\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"\\nUpdated DataFrame saved to: {output_file_path}\")"
   ],
   "id": "2b820b39ee611eb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated DataFrame saved to: highlighted_duplicates_with_row_numbers.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:32:40.686378Z",
     "start_time": "2024-12-22T14:32:40.442820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove the rows that are marked as duplicates\n",
    "df_filtered = df[df['is_duplicate'] != 'Duplicate']\n",
    "\n",
    "# Count the total number of rows after removing duplicates\n",
    "total_rows_after_removal = df_filtered.shape[0]\n",
    "print(f\"\\nTotal number of rows after removing duplicates: {total_rows_after_removal}\")\n",
    "\n",
    "# Save the filtered DataFrame (without duplicates) to the original file or a new file\n",
    "filtered_file_path = 'cleaned data.csv'  # Replace with the desired output file path\n",
    "df_filtered.to_csv(filtered_file_path, index=False)\n",
    "print(f\"\\nFiltered DataFrame (without duplicates) saved to: {filtered_file_path}\")"
   ],
   "id": "77ad6b1449053747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of rows after removing duplicates: 38931\n",
      "\n",
      "Filtered DataFrame (without duplicates) saved to: cleaned data.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:11:12.295953Z",
     "start_time": "2024-12-22T15:11:06.110598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"cleaned data.csv\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['y'])  # Features\n",
    "y = df['y']  # Target\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")\n",
    "\n",
    "# Neural Network Classifier\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, random_state=42)\n",
    "nn_model.fit(X_train, y_train)\n",
    "nn_predictions = nn_model.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, nn_predictions)\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy:.2f}\")\n",
    "\n",
    "# Assess dataset readiness\n",
    "if rf_accuracy > 0.75 and nn_accuracy > 0.75:\n",
    "    print(\"The dataset is likely ready for prediction.\")\n",
    "else:\n",
    "    print(\"Further preprocessing or feature engineering may be required.\")"
   ],
   "id": "17b5b4a4f395ce5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.89\n",
      "Neural Network Accuracy: 0.87\n",
      "The dataset is likely ready for prediction.\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
